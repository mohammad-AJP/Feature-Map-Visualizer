
# Convolutional Layer Output Visualizer

You are able to visualize intermediate convolution layers' output feature maps using this repository.




## Convolutional Neural Networks

Convolutional neural networks have shown promissing performances in various computer vision tasks, from image segmentation to high level tasks such as video recognition (3D data) and fMRI (4D data). CNN models learn features of the training images with various filters applied at each layer. The features learned at each convolutional layer significantly vary. It is an observed fact that initial layers predominantly capture edges, the orientation of image and colours in the image which are low-level features. With an increase in the number of layers, CNN captures high-level features which help differentiate between various classes of images.   

To understand how convolutional neural networks learn spatial and temporal dependencies of an image, different features captured at each layer can be visualized using the codes in this repo.
## ResNet50 and VGG19

Two popular convolutional architectures called ResNet50 and VGG19 are used here to show how they learn from the imput layer to the output layer by extracting their intermediate convolutional layers' outputs and plooting them as an image.   
 
Below are the structurez of ResNet50 and VGG19 architecture:

## ResNet Architecture

![ResNet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/arcres.JPG)

As it can be seen in ResNet architecture, the main idea which resulted in resnet's brilliant perforemance is skip connection or shortcuts in each block. In fact, although increasing depth of the network helps the system to show a better perforemance, it causes vanishing gradient problem. It means that the model's weights of the first layers can not be updated correctly through the backpropagation of the error gradient. In other words, the chain rule multiplies error gradient values lower than one and then, when the gradient error comes to the first layers, its value goes to zero. ResNet aims to solve this problem and preserve the gradient using skip connections. It plays the role of an identity matrix and when backpropagating through the identity function, the gradient would simply be multiplied by 1 and nothing would happen to it. This subject is out of scope of this repo and for further information, I recommend studying the original paper.   
Here is the picture of one resnet block with skip connections:   
![skip connection](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/skip%20connection.JPG)

## VGG19 Architecture

![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/arcvgg.JPG)

## Observing Intermediate feature maps
The output of each convolutional layer is called a feature map. Feature maps are generated by applying various filters to the inputs. The concept of filters and convolutions have existed long before convolutional neural networks. However, what makes CNNs superior to traditional computer vision algorithms is that in the latter, the filters weights were fixed and calculated by a scientist, but in the former, filters weights are learned through the learning process, making them very powerful and task specific. 

### How learning happens across CNNs?
At the start of the convolutional network, the types of filters (aka: kerners or feature detectors) are quite simple and more geometric, detecting features such as edges, corners, horizontal/vertical lines, simple shapes and patterns.    

In later layers, more complex filters are incorporated that detect shapes, objects and other complex structures, This is done by leveraging the previously generated feature maps and their detected simple features to build more complex ones.    

Below are ResNet50 and VGG19's intermediate feature maps. Looking at their progress in different layers all the way from input to the output will prove the previous paragraphs.
### Input image
I used an image of cat as the input to the network. Here you can see the image: 
![input image](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/cat.jpg)

### ResNet50 intermediate feature maps
Here are feature maps extracted from convolutional layers : 2, 45, 87, 129, 171

![resnet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/R2.JPG)
![resnet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/R45.JPG)
![resnet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/R87.JPG)
![resnet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/R129.JPG)
![resnet Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/R171.JPG)

### VGG19 intermediate feature maps
Here are feature maps extracted from convolutional layers : 2, 5, 10, 15, 20

![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/v2.JPG)
![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/v5.JPG)
![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/v10.JPG)
![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/v15.JPG)
![VGG19 Architecture](https://github.com/mohammad-AJP/Feature-Map-Visualizer/blob/main/Screenshots/v20.JPG)

### Results
As can be seen in above pictures, first convolutional layers detect simple features and gradually, with an increase in the depth, the complexity of detected features increases.   

You can play with code, change the CNN architecture, change the number of feature maps and the layer from which feature maps are extracted to achieve a better intuition of the learning process in Convolutional Neural Networks. 
Hope you enjoy!
